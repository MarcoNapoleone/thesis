{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages successfully loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# Convolutional Neural Network (CNN)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "\n",
    "print('All packages successfully loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Data & Peak Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nova/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(968, 192)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"/Users/nova/Desktop/Thesis/Metabolomics ML/data/MTBLS90.xlsx\", index_col=\"Idx\")\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract X & Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['SampleID', 'Sex', 'Class'])\n",
    "y = df.Class\n",
    "\n",
    "# Suddividiamo i dati in training e test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "# Effettuiamo il reshape dei dati per adattarli alla CNN unidimensionale\n",
    "X_train = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Build Model & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.2174 - accuracy: 0.5129 - val_loss: 0.7312 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6956 - accuracy: 0.5310 - val_loss: 0.7176 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.5297 - val_loss: 0.6694 - val_accuracy: 0.6392\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7232 - accuracy: 0.5362 - val_loss: 0.7224 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.5943 - val_loss: 0.6391 - val_accuracy: 0.6907\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.5724 - val_loss: 0.6185 - val_accuracy: 0.6959\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.6034 - val_loss: 0.6603 - val_accuracy: 0.5567\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.6059 - val_loss: 0.5913 - val_accuracy: 0.7062\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6602 - val_loss: 0.5993 - val_accuracy: 0.6598\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.7261 - val_loss: 0.5691 - val_accuracy: 0.7371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x295b8c310>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definiamo il modello CNN\n",
    "model = Sequential([\n",
    "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(189, 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compiliamo il modello\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Addestriamo il modello\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 948us/step\n",
      "Accuratezza: 0.7371134020618557\n",
      "Precision: 0.7129629629629629\n",
      "Recall: 0.7938144329896907\n",
      "F1-Score: 0.751219512195122\n",
      "Matrice di Confusione:\n",
      "[[66 31]\n",
      " [20 77]]\n",
      "ROC AUC: 0.7371134020618556\n"
     ]
    }
   ],
   "source": [
    "# Utilizziamo il metodo \"predict\" per ottenere le probabilitÃ  delle classi\n",
    "y_pred_1 = model.predict(X_test)\n",
    "# Applichiamo di una soglia di decisione (ad esempio, 0.5) per ottenere le classi previste\n",
    "y_pred = (y_pred_1 > 0.5).astype(int)\n",
    "\n",
    "# Calcoliamo le metriche del modello appena addestrato\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred)\n",
    "recall = metrics.recall_score(y_test, y_pred)\n",
    "f1 = metrics.f1_score(y_test, y_pred)\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Stampiamo le metriche\n",
    "print(f'Accuratezza: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-Score: {f1}')\n",
    "print(f'Matrice di Confusione:\\n{conf_matrix}')\n",
    "print(f'ROC AUC: {roc_auc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
